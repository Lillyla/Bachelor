{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Derivative:\n",
    "    \"\"\" Enabling the usage of +, *, -, etc. \"\"\"\n",
    "    def __add__(self, other):\n",
    "        return Add(self, other)\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        return rAdd(self, other)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        return Sub(self, other)\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return rSub(self, other)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return Mul(self, other)\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return rMul(self, other)\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        return Div(self, other)\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        return rDiv(self, other)\n",
    "   \n",
    "    def Sin(self):\n",
    "        return Sin(self)\n",
    "    \n",
    "    def __pow__(self, power):\n",
    "        return Pow(self, power)\n",
    "    \n",
    "    def Exp(self):\n",
    "        return Exp(self)\n",
    "    \n",
    "    def Cdf(self):\n",
    "        return Cdf(self)\n",
    "    \n",
    "    def __ge__(self, other):\n",
    "        return Ge(self, other)\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        return Le(self, other)\n",
    "    \n",
    "    def __hash__(self):                 # we need this for creating the dictionary with keys as Derivatives object\n",
    "        return hash(str(self))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaf nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Var(Derivative):\n",
    "    \"\"\" A leaf node (a node which doesn't have any child) \"\"\"\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value      # the scalar value of the node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Derivative):\n",
    "    \"\"\" The node that results from adding two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float, np.ndarray)): \n",
    "            self.value = node_a + node_b.value\n",
    "            self.grad = [(node_b, 1)]\n",
    "        elif isinstance(node_b, (int, float, np.ndarray)): \n",
    "            self.value = node_a.value + node_b\n",
    "            self.grad = [(node_a, 1)]\n",
    "        else:      \n",
    "            self.value = node_a.value + node_b.value    # value of the node\n",
    "            self.grad = [(node_a, 1), (node_b, 1)]      # partial derivatives of nodes - value 1 for derivative in respect to node_a and 1 for node_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rAdd(Derivative):\n",
    "    \"\"\" The node that results from adding two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a + node_b.value\n",
    "            self.grad = [(node_b, 1)]\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value + node_b\n",
    "            self.grad = [(node_a, 1)]\n",
    "        else:      \n",
    "            self.value = node_a.value + node_b.value    # value of the node\n",
    "            self.grad = [(node_a, 1), (node_b, 1)]      # partial derivatives of nodes - value 1 for derivative in respect to node_a and 1 for node_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substract the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sub(Derivative):\n",
    "    \"\"\" The node that results from subtracting two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a - node_b.value\n",
    "            self.grad = [(node_b, -1)]\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value - node_b\n",
    "            self.grad = [(node_a, 1)]\n",
    "        else:      \n",
    "            self.value = node_a.value - node_b.value    # value of the node\n",
    "            self.grad = [(node_a, 1), (node_b, -1)]     # partial derivatives of nodes - should have again the structure as [(node_a, value), (node_b, value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rSub(Derivative):\n",
    "    \"\"\" The node that results from subtracting two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a - node_b.value\n",
    "            self.grad = [(node_b, -1)]\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value - node_b\n",
    "            self.grad = [(node_a, 1)]\n",
    "        else:      \n",
    "            self.value = node_a.value - node_b.value    # value of the node\n",
    "            self.grad = [(node_a, 1), (node_b, -1)]     # partial derivatives of nodes - should have again the structure as [(node_a, value), (node_b, value)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplication of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mul(Derivative):\n",
    "    \"\"\" The node that results from multiplying two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float, np.ndarray)): \n",
    "            self.value = node_a * node_b.value\n",
    "            self.grad = [(node_b, node_a)]\n",
    "        elif isinstance(node_b, (int, float, np.ndarray)): \n",
    "            self.value = node_a.value * node_b\n",
    "            self.grad = [(node_a, node_b)]\n",
    "        else:      \n",
    "            self.value = node_a.value * node_b.value\n",
    "            self.grad = [(node_a, node_b.value), (node_b, node_a.value)]        # f = x*y   df / dx = y   df / dy = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rMul(Derivative):\n",
    "    \"\"\" The node that results from multiplying two nodes \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float, np.ndarray)): \n",
    "            self.value = node_a * node_b.value\n",
    "            self.grad = [(node_b, node_a)]\n",
    "        elif isinstance(node_b, (int, float, np.ndarray)): \n",
    "            self.value = node_a.value * node_b\n",
    "            self.grad = [(node_a, node_b)]\n",
    "        else:      \n",
    "            self.value = node_a.value * node_b.value\n",
    "            self.grad = [(node_a, node_b.value), (node_b, node_a.value)]                                # f = x*y   df / dx = y   df / dy = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Div(Derivative):\n",
    "    \"\"\" The node that results from dividing one node by another \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a / node_b.value\n",
    "            self.grad = [(node_b, -node_a/(node_b.value**2))]\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value / node_b\n",
    "            self.grad = [(node_a, 1/node_b)]\n",
    "        else:      \n",
    "            self.value = node_a.value / node_b.value\n",
    "            self.grad = [(node_a, 1/node_b.value), (node_b, -node_a.value/(node_b.value**2))]           # f = x/y   df / dx = 1/y    df / dy = -x / (y^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rDiv(Derivative):\n",
    "    \"\"\" The node that results from dividing one node by another \"\"\"\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a / node_b.value\n",
    "            self.grad = [(node_b, -node_a/(node_b.value**2))]\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value / node_b\n",
    "            self.grad = [(node_a, 1/node_b)]\n",
    "        else:      \n",
    "            self.value = node_a.value / node_b.value\n",
    "            self.grad = [(node_a, 1/node_b.value), (node_b, -node_a.value/(node_b.value**2))]           # f = x/y   df / dx = 1/y    df / dy = -x / (y^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logarithm of one mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log(Derivative):\n",
    "    \"\"\" The node that results from sin(node) \"\"\"\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = np.log(node) \n",
    "            self.grad = [(node, 0)]\n",
    "        else:\n",
    "            self.value = np.log(node.value)                          \n",
    "            self.grad = [(node, 1/node.value)]                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinus of one node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sin(Derivative):\n",
    "    \"\"\" The node that results from sin(node) \"\"\"\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = np.sin(node) \n",
    "            self.grad = [(node, 0)]\n",
    "        else:\n",
    "            self.value = np.sin(node.value)                          # use np.sin() function\n",
    "            self.grad = [(node, np.cos(node.value))]                 # only one derivative, since it takes only one node - use np.cos() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosinus of one node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cos(Derivative):\n",
    "    \"\"\" The node that results from cos(node) \"\"\"\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = np.cos(node)\n",
    "            self.grad = [(node, 0)]\n",
    "        else:\n",
    "            self.value = np.cos(node.value)                          \n",
    "            self.grad = [(node, -np.sin(node.value))]                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pow(Derivative):\n",
    "    \"\"\" The node that results as node ^ power \"\"\"\n",
    "    \n",
    "    def __init__(self, node, power):\n",
    "        self.value = node.value**power                                         # reminder of power operation in python: **\n",
    "        self.grad = [(node, power*node.value**(power-1))]                      # (one derivative)    f = x^n   df/dx = n * x ^ (n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp(Derivative):\n",
    "    \"\"\" The node that results from exp(node) \"\"\"\n",
    "\n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = np.exp(node)  \n",
    "            self.grad = [(node, 0)]\n",
    "        else:\n",
    "            self.value = np.exp(node.value)                         \n",
    "            self.grad = [(node, np.exp(node.value))]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpK(Derivative):\n",
    "    \"\"\" The node that results from exp(k*node) \"\"\"\n",
    "    \n",
    "    def __init__(self, node, k):\n",
    "        self.value = np.exp(k*node)                          \n",
    "        self.grad = [(node, k*np.exp(k*node))]                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Squareroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sqrt(Derivative):\n",
    "    \"\"\" The node that results from sqrt(node) \"\"\"\n",
    "    \n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = np.sqrt(node)\n",
    "            self.grad = [(node, 0)]\n",
    "        else:\n",
    "            self.value = np.sqrt(node.value)                  \n",
    "            self.grad = [(node, 1/(2*np.sqrt(node.value)))]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ a^x $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pot(Derivative):\n",
    "    \"\"\" The node that results from a ^ node \"\"\"\n",
    "    \n",
    "    def __init__(self, a, node):\n",
    "        self.value = a**node.value                          \n",
    "        self.grad = [(node, a**node.value * np.log(a))]                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cdf(Derivative):\n",
    "    \"\"\" The node that results from cdf(node) \"\"\"\n",
    "\n",
    "    def __init__(self, node):\n",
    "        if isinstance(node, (int, float)): \n",
    "            self.value = norm.cdf(node) \n",
    "            self.grad = [(node, norm.pdf(node) )]\n",
    "        else:\n",
    "            self.value = norm.cdf(node.value)            \n",
    "            self.grad = [(node, norm.pdf(node.value))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overskrivning af >= og <="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ge(Derivative):\n",
    "    \"\"\" >= \"\"\"\n",
    "            \n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a >= node_b.value\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value >= node_b\n",
    "        else:      \n",
    "            self.value = node_a.value >= node_b.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Le(Derivative):\n",
    "    \"\"\" <= \"\"\"\n",
    "\n",
    "    def __init__(self, node_a, node_b):\n",
    "        if isinstance(node_a, (int, float)): \n",
    "            self.value = node_a <= node_b.value\n",
    "        elif isinstance(node_b, (int, float)): \n",
    "            self.value = node_a.value <= node_b\n",
    "        else:      \n",
    "            self.value = node_a.value <= node_b.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function for getting the gradients values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Gradient(parent_node):\n",
    "    \"\"\" Go down the graph, and compute derivative of `parent_node` with respect to each node \"\"\"\n",
    "    \n",
    "    # we will create a dictionary 'gradient' which will have the nodes as keys and its derivatives as values\n",
    "    gradients = defaultdict(lambda: 0)    # initialize the dictionary so when calling a non-existing key the value of 0 is assigned\n",
    "    \n",
    "    # stack will represent the list of tuples (node, node_derivative) \n",
    "    stack = parent_node.grad.copy()     \n",
    "    \n",
    "    while stack:                             # loop for each different branch\n",
    "        # get node and node_derivative from the top of the stack - function pop()\n",
    "        temp = stack.pop()                   \n",
    "        node = temp[0]\n",
    "        node_derivative = temp[1]            \n",
    "        # add to the value of derivative of the node (gradients[node]) value node_derivative\n",
    "        gradients[node] = gradients[node] + node_derivative  \n",
    "        \n",
    "        if not isinstance(node, Var):        # if the node has children, put them onto the stack\n",
    "            # loop for each node in one branch\n",
    "            for child_node, child_node_derivative in node.grad:                   \n",
    "                # append child_node and child_node_derivative * node_derivative to the stack\n",
    "                stack.append((child_node, child_node_derivative * node_derivative))\n",
    "                \n",
    "    return dict(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Black-Scholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style \n",
    "style.use('ggplot')\n",
    "from scipy.stats import norm\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euro_call(S0, K, T, r, sigma):\n",
    "    d1 = (Log(S0/K)+(r+1/2*(sigma**2))*T)/(sigma*Sqrt(T))\n",
    "    d2 = d1 - sigma*Sqrt(T)\n",
    "    return S0 * Cdf(d1)  - K * Exp((-1)*r * T) * Cdf(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_val = 100\n",
    "K_val = 100\n",
    "T_val = 1\n",
    "r_val = 0.07\n",
    "sigma_val = 0.2\n",
    "n_simulations = 1000\n",
    "n_steps = 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of f equals 11.541470170672412\n",
      "The partial derivative of y with respect to S0 = 0.6736447797120796\n",
      "The partial derivative of y with respect to K = -0.5582300780053555\n",
      "The partial derivative of y with respect to T = 7.512880170653974\n",
      "The partial derivative of y with respect to r = 55.82300780053558\n",
      "The partial derivative of y with respect to sigma = 36.05269624616482\n"
     ]
    }
   ],
   "source": [
    "S0 = Var(S0_val)\n",
    "K = Var(K_val)\n",
    "T = Var(T_val)\n",
    "r = Var(r_val)\n",
    "sigma = Var(sigma_val)\n",
    "\n",
    "y = euro_call(S0, K, T, r, sigma)\n",
    "gradients = Get_Gradient(y)\n",
    "\n",
    "print('Value of f equals', y.value)\n",
    "print('The partial derivative of y with respect to S0 =', gradients[S0])\n",
    "print('The partial derivative of y with respect to K =', gradients[K])\n",
    "print('The partial derivative of y with respect to T =', gradients[T])\n",
    "print('The partial derivative of y with respect to r =', gradients[r])\n",
    "print('The partial derivative of y with respect to sigma =', gradients[sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
